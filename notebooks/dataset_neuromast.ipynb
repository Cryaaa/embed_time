{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iohub.ngff import open_ome_zarr\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "from pathlib import Path \n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.ndimage import measurements\n",
    "from scipy.ndimage import center_of_mass\n",
    "import numpy as np\n",
    "\n",
    "zarr_dir = \"/mnt/efs/dlmbl/G-et/data/neuromast/Dataset/\"\n",
    "# defines input zarr file name with the zarr file structure\n",
    "zarr_file = 'structured_celltype_classifier_data.zarr/*/*/*'\n",
    "position_paths = natsorted(glob(zarr_dir + zarr_file))\n",
    "# print(position_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positions:  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of positions: \", len(position_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = open_ome_zarr(position_paths[0], mode=\"r\")\n",
    "dataset.data.shape\n",
    "all_chan = dataset.channel_names\n",
    "chan = 'celltypes'\n",
    "all_chan.index(chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuromastDataset(Dataset):\n",
    "    def __init__(self, file_path, class_channel: str = 'celltypes'):\n",
    "        self.file_path = file_path\n",
    "        #get the class index\n",
    "        dataset = open_ome_zarr(self.file_path[0], mode=\"r\")\n",
    "        all_chan = dataset.channel_names\n",
    "        self.c = all_chan.index(class_channel)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset = open_ome_zarr(position_paths[idx], mode=\"r\")\n",
    "        image = dataset.data[:,0:self.c,:,:,:]\n",
    "        label = dataset.data[:,self.c:self.c+1,:,:,:]\n",
    "        return image, label\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 73, 1024, 1024)\n",
      "(1, 1, 73, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "neuromast = NeuromastDataset(position_paths, class_channel='celltypes')\n",
    "print(neuromast[0][0].shape)\n",
    "print(neuromast[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135839/513073290.py:2: DeprecationWarning: Please import `binary_dilation` from the `scipy.ndimage` namespace; the `scipy.ndimage.morphology` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.morphology import binary_dilation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = open_ome_zarr(position_paths[0], mode=\"r\")\n",
    "\n",
    "\n",
    "all_chan = dataset.channel_names\n",
    "chan = 'celltypes'\n",
    "c = all_chan.index(chan)\n",
    "\n",
    "image = dataset.data[:,0:c,:,:,:]\n",
    "celltype = dataset.data[0,c:c+1,:,:,:]\n",
    "segmented_data = dataset.data[0,2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords [[  5   5   5 ...  44  44  44]\n",
      " [359 359 359 ... 385 386 386]\n",
      " [508 509 510 ... 512 505 506]]\n",
      "centroid [ 22.28359574 364.65511098 507.8500329 ]\n",
      "coords [[  5   5   5 ...  46  46  46]\n",
      " [397 397 397 ... 383 384 384]\n",
      " [453 454 455 ... 442 438 439]]\n",
      "centroid [ 21.6632611  392.1020675  445.27676021]\n",
      "{np.float32(1.0): array([ 22.28359574, 364.65511098, 507.8500329 ]), np.float32(2.0): array([ 21.6632611 , 392.1020675 , 445.27676021])}\n"
     ]
    }
   ],
   "source": [
    "segment_labels = np.unique(segmented_data)\n",
    "segment_labels = segment_labels[segment_labels != 0]  # Exclude background\n",
    "\n",
    "centroids = {}\n",
    "\n",
    "# Calculate the centroid for each segment\n",
    "for label in segment_labels:\n",
    "    # Get a binary mask of the current segment\n",
    "    segment_mask = segmented_data == label\n",
    "    \n",
    "    # Compute the centroid\n",
    "    coords = np.array(np.nonzero(segment_mask))\n",
    "    print(\"coords\",coords)  # Get the coordinates of the segment\n",
    "    centroid = np.mean(coords, axis=1)\n",
    "    print(\"centroid\", centroid)   # Calculate the mean along each axis (Z, Y, X)\n",
    "    centroids[label] = centroid\n",
    "    \n",
    "    # Store the centroid\n",
    "    centroids[label] = centroid\n",
    "    if  label ==2:\n",
    "        break\n",
    "\n",
    "# Now, centroids dictionary holds the centroid for each segment label\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
