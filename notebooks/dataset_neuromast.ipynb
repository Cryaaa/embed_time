{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iohub.ngff import open_ome_zarr\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "from pathlib import Path \n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "zarr_dir = \"/mnt/efs/dlmbl/G-et/data/neuromast/Dataset/\"\n",
    "# defines input zarr file name with the zarr file structure\n",
    "zarr_file = 'structured_celltype_classifier_data.zarr/*/*/*'\n",
    "position_paths = natsorted(glob(zarr_dir + zarr_file))\n",
    "# print(position_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positions:  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of positions: \", len(position_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = open_ome_zarr(position_paths[0], mode=\"r\")\n",
    "dataset.data.shape\n",
    "all_chan = dataset.channel_names\n",
    "chan = 'celltypes'\n",
    "all_chan.index(chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuromastDataset(Dataset):\n",
    "    def __init__(self, file_path, class_channel: str = 'celltypes'):\n",
    "        self.file_path = file_path\n",
    "        #get the class index\n",
    "        dataset = open_ome_zarr(self.file_path[0], mode=\"r\")\n",
    "        all_chan = dataset.channel_names\n",
    "        self.c = all_chan.index(class_channel)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset = open_ome_zarr(position_paths[idx], mode=\"r\")\n",
    "        image = dataset.data[:,0:self.c,:,:,:]\n",
    "        label = dataset.data[:,self.c:self.c+1,:,:,:]\n",
    "        return image, label\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 73, 1024, 1024)\n",
      "(1, 1, 73, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "neuromast = NeuromastDataset(position_paths, class_channel='celltypes')\n",
    "print(neuromast[0][0].shape)\n",
    "print(neuromast[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97688/774659179.py:2: DeprecationWarning: Please import `binary_dilation` from the `scipy.ndimage` namespace; the `scipy.ndimage.morphology` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.morphology import binary_dilation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  5.  8.  9. 10. 15. 16. 17. 18. 19. 24. 25. 26. 27. 28. 29.\n",
      " 30. 31. 34. 35. 36. 37. 38. 41. 42. 45. 46. 47. 48. 49. 50. 51. 52. 53.\n",
      " 54. 57. 60. 61. 62. 63. 64. 65. 66. 67. 68. 70. 71.]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 4 is out of bounds for array of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m unique \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(segments)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique)\n\u001b[0;32m---> 16\u001b[0m segment_sizes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(segment_sizes)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# dilated_segments = binary_dilation(segments)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# segment_sizes = []\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# for segment in segments:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     size = np.sum(segment)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     segment_sizes.append(size)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(segment_sizes)\n",
      "File \u001b[0;32m~/miniforge3/envs/embed_time/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:2485\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2486\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\n\u001b[1;32m   2488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/embed_time/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 4 is out of bounds for array of dimension 4"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "dataset = open_ome_zarr(position_paths[0], mode=\"r\")\n",
    "dataset.data.shape\n",
    "all_chan = dataset.channel_names\n",
    "chan = 'celltypes'\n",
    "c = all_chan.index(chan)\n",
    "\n",
    "image = dataset.data[:,0:c,:,:,:]\n",
    "label = dataset.data[:,c:c+1,:,:,:]\n",
    "segments = dataset.data[:,2]\n",
    "\n",
    "\n",
    "unique = np.unique(segments)\n",
    "print(unique)\n",
    "segment_sizes = np.sum(segments, axis=(1, 2, 3, 4))\n",
    "# print(segment_sizes)\n",
    "# dilated_segments = binary_dilation(segments)\n",
    "# segment_sizes = []\n",
    "# for segment in segments:\n",
    "#     size = np.sum(segment)\n",
    "#     segment_sizes.append(size)\n",
    "print(segment_sizes)\n",
    "# print(dilated_segments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
